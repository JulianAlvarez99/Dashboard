# Planificaci√≥n Arquitect√≥nica V2.0 ‚Äî Camet Analytics

**Descripci√≥n:** Esta es la hoja de ruta detallada para la refactorizaci√≥n completa del SaaS de monitoreo industrial. El objetivo principal es lograr una arquitectura altamente escalable, basada en plugins (Registry Pattern), con control estricto de memoria (Data Scoping) y un intermediario inteligente de datos (Data Broker). Todo optimizado para un entorno de hosting compartido en cPanel.

---

## üèóÔ∏è Nuevos Paradigmas Arquitect√≥nicos

Antes de iniciar con las etapas de desarrollo, el sistema se regir√° por tres principios inquebrantables:

1. **Registry Pattern (Cero Acoplamiento):** Eliminaci√≥n total de diccionarios de mapeo gigantes o sentencias condicionales largas para definir qu√© filtro o widget usar. La base de datos almacenar√° el nombre exacto de la clase o funci√≥n a instanciar, y el sistema la cargar√° din√°micamente mediante reflexi√≥n/introspecci√≥n.
2. **Data Scoping (Eficiencia de Memoria):** Los widgets son consumidores estrictos. Exigir√°n exactamente qu√© columnas del DataFrame Maestro o qu√© datos externos necesitan. Nunca se enviar√° un DataFrame completo si un widget solo grafica dos variables.
3. **Data Broker (Aislamiento de Fuentes):** Ning√∫n widget sabr√° c√≥mo ir a buscar sus datos. Una capa intermedia (el Orquestador de Datos) leer√° el origen del widget (interno de MySQL o externo de una API) y le entregar√° la informaci√≥n ya recolectada.

---

## üì¶ ETAPA 1: Fundaciones Core, Autenticaci√≥n y Cach√© (La Infraestructura Base)

**Objetivo:** Establecer la base dual del proyecto garantizando que las consultas repetitivas no golpeen la base de datos de cPanel.

* **Fase 1.1: Setup Dual-Server**
* Configurar el punto de entrada principal para lanzar FastAPI (Motor de Datos) y Flask (Renderizado SSR) como hilos/procesos independientes compatibles con WSGI/ASGI.


* **Fase 1.2: DatabaseManager Optimizado**
* Implementar el gestor de base de datos multi-tenant utilizando una estrategia sin pooling (`NullPool`) para evitar agotar las conexiones limitadas de cPanel.


* **Fase 1.3: Autenticaci√≥n y Seguridad**
* Replicar el sistema de login seguro usando Argon2.
* Implementar control de sesi√≥n h√≠brido (Server-side en Flask, validaci√≥n JWT en FastAPI).


* **Fase 1.4: Metadata Cache Singleton**
* Desarrollar el servicio que, al iniciar la aplicaci√≥n o al detectar un inicio de sesi√≥n de un tenant nuevo, cargue toda la configuraci√≥n est√°tica en memoria RAM (L√≠neas, √Åreas, Productos, Turnos).



---

## üéõÔ∏è ETAPA 2: Motor de Filtros Din√°micos (Patr√≥n Registry)

**Objetivo:** Simplificar la creaci√≥n y renderizado de filtros. Cada filtro ser√° un m√≥dulo independiente.

* **Fase 2.1: Interfaz Base de Filtros (`BaseFilter`)**
* Definir la estructura obligatoria para todo filtro, incluyendo los m√©todos de validaci√≥n de entrada del usuario, la recolecci√≥n de opciones est√°ticas, y la generaci√≥n de fragmentos de SQL.


* **Fase 2.2: Implementaci√≥n de Filtros Concretos**
* Crear clases independientes para cada tipo (Ej: `FiltroFechas`, `FiltroDropdownMulti`, `FiltroToggle`).


* **Fase 2.3: Inyecci√≥n desde Cach√©**
* Conectar las clases de los filtros din√°micos (como la lista de productos o l√≠neas) directamente con el `MetadataCache` para que sus opciones de selecci√≥n se generen en microsegundos sin consultas a MySQL.


* **Fase 2.4: Auto-Registro de Filtros**
* Configurar el motor para que lea la tabla `Filters` y, utilizando el nombre de la clase all√≠ guardado, instancie din√°micamente el filtro correspondiente para el usuario actual.



---

## ‚öôÔ∏è ETAPA 3: Extracci√≥n de Datos Internos (El Data Lake Local)

**Objetivo:** Aislar la obtenci√≥n y cruzamiento de los datos nativos de la planta de producci√≥n.

* **Fase 3.1: Constructor de Consultas Din√°mico (Query Builder)**
* Desarrollar el generador de sentencias SQL que consolide todos los fragmentos creados por los filtros activados por el usuario.
* Mantener el soporte automatizado para el ruteo de particiones mensuales.


* **Fase 3.2: Extracci√≥n y Conversi√≥n**
* Ejecutar la consulta en las tablas de detecciones de la l√≠nea seleccionada y convertir la respuesta cruda en un DataFrame base de Pandas de alta velocidad.


* **Fase 3.3: Application-Side Joins (Enriquecimiento)**
* Tomar el DataFrame base y cruzarlo en memoria (Python-side) con el `MetadataCache` para inyectar nombres legibles, c√≥digos de producto, √°reas y pesos, formando as√≠ el "DataFrame Maestro".



---

## üåê ETAPA 4: Data Broker y APIs Externas (El Orquestador de Fuentes)

**Objetivo:** Crear una capa intermedia inteligente que controle de d√≥nde proviene la informaci√≥n, permitiendo combinar datos de los sensores de la planta con APIs de terceros.

* **Fase 4.1: Archivo de Configuraci√≥n Externo (`external_apis.yml`)**
* Crear el manifiesto YAML que define las URLs base, los m√©todos HTTP admitidos, los tiempos m√°ximos de espera (timeouts) y los nombres de las variables de entorno que guardan los tokens de seguridad para cada API externa (ERP, Clima, Cotizaciones, etc.).


* **Fase 4.2: Cliente HTTP As√≠ncrono (`ExternalAPIService`)**
* Implementar un servicio centralizado basado en un cliente no bloqueante que consuma las APIs del archivo YAML, con un manejo estricto de errores para evitar que una ca√≠da externa cuelgue el dashboard interno.


* **Fase 4.3: Implementaci√≥n del Data Broker**
* Construir el enrutador l√≥gico que determine el proveedor de datos.
* Establecer la l√≥gica de evaluaci√≥n: Si un widget indica fuente "interna", se le asigna el DataFrame Maestro. Si indica fuente "externa", dispara la solicitud as√≠ncrona a la API correspondiente.



---

## üìä ETAPA 5: Motor de Widgets Independientes (Data Scoping y Registry)

**Objetivo:** Transformar los widgets en componentes tontos pero altamente eficientes, ignorantes del origen general de los datos.

* **Fase 5.1: Interfaz Base de Widgets (`BaseWidget`)**
* Definir la clase madre que obligue a especificar la fuente de datos (`source_type = 'internal' | 'external'`).
* Obligar la implementaci√≥n del m√©todo de requerimientos (ej. `required_columns` para datos internos o `required_api_id` para externos).


* **Fase 5.2: Procesador de Formato (`process_data`)**
* Establecer el m√©todo donde ocurre la magia algor√≠tmica. Este m√©todo recibe datos recortados (Data Scoping) y debe devolver √∫nicamente la estructura JSON (diccionario) formateada lista para Chart.js o el renderizador HTML.


* **Fase 5.3: Creaci√≥n del Cat√°logo y Auto-Registro**
* Implementar las clases concretas de cada widget (KPIs, L√≠neas, Barras) e instruir al motor para que las invoque din√°micamente seg√∫n lo indicado en la tabla `Widget_catalog`.



---

## üéº ETAPA 6: El Orquestador Principal (Dashboard Execution Workflow)

**Objetivo:** Construir la "gran v√≠a" que une todas las etapas anteriores en una √∫nica solicitud de red eficiente al presionar "Aplicar Filtros".

* **Fase 6.1: Recepci√≥n y Validaci√≥n**
* El endpoint maestro recibe el diccionario de opciones elegidas por el usuario.
* Valida las selecciones utilizando las reglas del Motor de Filtros (Etapa 2).


* **Fase 6.2: Construcci√≥n del Contexto de Datos**
* Dispara el Query Builder y enriquece los datos internos (Etapa 3) para crear el DataFrame Maestro.


* **Fase 6.3: Ruteo del Data Broker**
* Lee la configuraci√≥n del layout del usuario para saber qu√© widgets se van a renderizar.
* Pasa la lista de widgets al Data Broker (Etapa 4) para que recolecte, paralelamente si es posible, la informaci√≥n externa necesaria y recorte el DataFrame Maestro seg√∫n el requerimiento exacto de cada widget interno.


* **Fase 6.4: Ejecuci√≥n y Ensamblaje**
* Invoca el m√©todo `process_data` de cada widget instanciado con su fragmento de informaci√≥n correspondiente.
* Empaqueta todas las respuestas de los widgets en un √∫nico gran diccionario JSON estructurado y lo retorna a la capa de presentaci√≥n.



---

## üñ•Ô∏è ETAPA 7: Capa de Presentaci√≥n (Frontend Din√°mico con Flask y HTMX)

**Objetivo:** Mantener el frontend ligero (Driven Configuration). El navegador renderiza exactamente lo que el backend ordena.

* **Fase 7.1: Renderizado Inicial y Panel de Filtros**
* Al hacer Login, Flask consulta al backend por la configuraci√≥n base y utiliza plantillas Jinja2 para pintar la estructura general.
* Utilizar Alpine.js para gestionar el estado local del formulario de filtros y preconfigurar fechas.


* **Fase 7.2: Ciclo de Interactividad HTMX**
* Configurar el formulario principal para interceptar el bot√≥n "Aplicar Filtros" enviando una petici√≥n as√≠ncrona POST v√≠a HTMX al orquestador (Etapa 6).


* **Fase 7.3: Inyecci√≥n de Partials y Chart.js**
* Procesar la respuesta del backend, que entregar√° fragmentos HTML (partials) con las tarjetas KPI y lienzos `<canvas>` con sus atributos `x-data` actualizados.
* Hacer que Alpine.js reaccione a los nuevos fragmentos y dibuje (o redibuje) los gr√°ficos con la librer√≠a Chart.js de forma suave y sin parpadeos completos de pantalla.



---

## üõ°Ô∏è ETAPA 8: Tareas en Segundo Plano, Seguridad y Despliegue

**Objetivo:** Finalizar la arquitectura de grado de producci√≥n asegurando el mantenimiento continuo de la aplicaci√≥n sin intervenci√≥n humana.

* **Fase 8.1: Trabajos en Segundo Plano (APScheduler)**
* Codificar la l√≥gica de "Gap Analysis" (algoritmo de paradas) y mantenimientos de base de datos (particionamiento mensual) en tareas as√≠ncronas aisladas de los hilos web principales.


* **Fase 8.2: Capas de Seguridad Cr√≠tica**
* Configurar e inyectar validaciones CSRF nativas.
* Aplicar Rate Limiting inteligente y sanitizaci√≥n de encabezados usando los est√°ndares OWASP.


* **Fase 8.3: Optimizaci√≥n para Entorno de Hosting (cPanel)**
* Configurar el script adaptador `passenger_wsgi.py` para enganchar correctamente el hilo de Flask y FastAPI con Apache/LiteSpeed.
* Establecer una estricta pol√≠tica de recolecci√≥n de basura (Garbage Collection) en la capa de datos de Pandas para evitar que los workers agoten el l√≠mite de RAM del hosting compartido tras consultas masivas.